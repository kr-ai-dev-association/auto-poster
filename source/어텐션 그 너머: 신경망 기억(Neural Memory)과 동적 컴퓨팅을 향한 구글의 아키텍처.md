어텐션 그 너머: 신경망 기억(Neural Memory)과 동적 컴퓨팅을 향한 구글의 아키텍처 혁신1. 서론: 트랜스포머의 유산과 구글의 새로운 해답2017년 구글의 "Attention Is All You Need"는 AI 시대를 열었으나, 2025년에 이르러 트랜스포머 아키텍처는 **2차 복잡도(Quadratic Complexity)**와 **고정된 가중치(Static Weights)**라는 두 가지 한계에 직면했습니다.[21] 구글은 이를 극복하기 위해 단순히 모델 크기를 키우는 것이 아니라, 아키텍처의 근본적인 메커니즘을 재설계하는 데 집중하고 있습니다.본 보고서는 구글 리서치(Google Research)와 구글 딥마인드(Google DeepMind)가 발표한 차세대 기술 중, Titans, Mixture-of-Depths, Infini-attention, JEST, Griffin/Hawk 등 검증된 핵심 연구만을 다룹니다.2. Titans: 추론 시점 암기(Test-Time Memorization)와 신경 기억2024년 12월 말 구글 리서치가 공개한 Titans는 트랜스포머의 가장 강력한 대안으로 꼽힙니다. 이 연구는 외부 연구인 'Test-Time Training (TTT)'과 개념적으로 유사하지만, 구글만의 독자적인 '신경 장기 기억(Neural Long-term Memory)' 모듈을 통해 차별화된 성능을 입증했습니다.[2]2.1. 핵심 메커니즘: 놀라움(Surprise)과 망각Titans는 모델이 추론(Inference)하는 동안에도 정보를 '기억(학습)'합니다. 이는 기존 트랜스포머가 추론 시점에는 학습된 지식을 고정적으로 사용하는 것과 대조적입니다.놀라움(Surprise) 지표: Titans는 들어오는 정보가 얼마나 예상 밖인지(Gradient)를 측정합니다. 모델이 예측하지 못한 '놀라운' 정보만이 장기 기억 모듈의 가중치 업데이트에 반영됩니다.적응형 망각(Adaptive Forgetting): 모든 정보를 기억할 수는 없으므로, **가중치 감쇠(Weight Decay)**와 게이팅 메커니즘을 통해 덜 중요한 정보는 점진적으로 잊혀지게 합니다. 이는 인간의 기억 처리 방식과 유사합니다.12.2. 세 가지 아키텍처 변형 (Variants)구글은 메모리 모듈의 활용 방식에 따라 세 가지 변형을 제안했습니다.3변형 모델특징구글의 연구 결과MAC (Memory as a Context)메모리를 추가적인 문맥(Context)으로 취급긴 문맥 처리에 유리하며 RMT(Recurrent Memory Transformer)의 확장 개념MAG (Memory as a Gate)게이팅 메커니즘으로 메모리 혼합메모리와 주 연산 경로를 비선형적으로 결합하여 정보 흐름 제어MAL (Memory as a Layer)메모리를 하나의 층(Layer)으로 통합가장 우수한 성능. 메모리 모듈 자체가 심층 신경망의 연산 층으로 기능함2.3. 성과 및 의의Titans는 200만 토큰 이상의 문맥 창(Context Window)을 처리하면서도 기존 트랜스포머보다 메모리 효율이 뛰어납니다. 특히 구글은 Titans가 외부의 선형 순환 모델(Linear RNNs)이나 Mamba 아키텍처보다 긴 문맥에서의 '바늘 찾기(Needle-in-a-Haystack)' 성능이 우수함을 입증했습니다.33. Mixture-of-Depths (MoD): 토큰별 동적 연산 배분**Mixture-of-Depths (MoD)**는 구글 딥마인드가 2024년 4월 발표한 기술로, 트랜스포머의 비효율적인 연산 자원 배분 문제를 해결했습니다. 모든 토큰에 동일한 계산을 수행하는 대신, 중요한 토큰에만 집중합니다.63.1. 라우팅(Routing)과 IsoFLOP 분석Top-k 라우팅: 각 레이어의 라우터가 토큰의 중요도를 평가하여, 상위 $k$개의 토큰(예: 전체의 12.5%)만 셀프 어텐션과 MLP 연산을 수행합니다.잔차 연결(Residual bypass): 선택받지 못한 토큰은 연산을 건너뛰고 잔차 연결을 통해 다음 레이어로 전달됩니다. 이를 통해 정보의 흐름은 유지하되 연산량은 획기적으로 줄입니다.83.2. MoDE: 깊이와 전문가의 결합구글은 MoD를 기존의 MoE(Mixture-of-Experts)와 결합한 MoDE 아키텍처도 제안했습니다. 이는 토큰을 '처리할지 말지(Depth)'와 '어떤 전문가에게 보낼지(Expert)'를 동시에 결정하여 효율성을 극대화합니다.10 이 기술은 구글의 Gemini 1.5 및 이후 모델의 효율성 기반이 된 것으로 추정됩니다.4. Infini-attention: 무한한 문맥과 압축 메모리구글 연구진(Tsendsuren Munkhdalai et al.)이 제안한 Infini-attention은 유계 메모리(Bounded Memory) 내에서 무한한 길이의 문맥을 처리하는 기술입니다.114.1. 압축 메모리(Compressive Memory) 기술기존 트랜스포머가 과거의 KV(Key-Value) 캐시를 모두 저장하다가 메모리 부족을 겪는 것과 달리, Infini-attention은 오래된 정보를 압축 메모리에 통합합니다.로컬 + 글로벌 하이브리드: 현재의 문맥은 표준적인 로컬 어텐션(Local Attention)으로 정밀하게 처리하고, 과거의 방대한 문맥은 선형 어텐션(Linear Attention) 기반의 압축 메모리에서 인출(Retrieval)합니다.13메모리 인출 수식:$$A_{mem} = \frac{\sigma(Q) M_{s-1}}{\sigma(Q) z_{s-1}}$$이 방식은 10억 파라미터(1B) 규모의 작은 모델로도 100만 토큰 길이의 'Passkey' 테스트를 통과하게 했습니다.115. JEST: 데이터 선별의 가속화모델 아키텍처뿐만 아니라 데이터 학습 방식에서도 구글 딥마인드는 **JEST (Joint Example Selection and Training)**를 통해 혁신을 이루었습니다.155.1. 학습 가능성(Learnability) 기반의 배치 선택JEST는 개별 데이터가 아니라 배치(Batch) 단위의 데이터 구성을 최적화합니다. 이를 위해 두 가지 모델을 사용합니다.참조 모델(Reference Model): 양질의 데이터로 사전 학습된 모델.학습 모델(Learner Model): 현재 학습 중인 모델.JEST는 "참조 모델은 잘 알지만(고품질), 학습 모델은 아직 모르는(높은 손실값)" 데이터 배치를 우선적으로 선별합니다.5.2. 효율성: 13배 빠른 학습이 방식은 무작위 배치 학습 대비 **13배 더 적은 반복(Iteration)**과 **10배 더 적은 연산(Compute)**만으로 동등한 성능에 도달했습니다. 이는 '데이터의 질'을 알고리즘적으로 평가하여 AI 학습 속도를 비약적으로 높인 구글 딥마인드의 핵심 성과입니다.176. Griffin & Hawk: RNN의 현대적 재해석구글 딥마인드는 트랜스포머의 대안으로 Griffin과 Hawk를 발표하며 순환신경망(RNN)을 부활시켰습니다.196.1. RG-LRU (Real-Gated Linear Recurrent Unit)이들 모델의 핵심은 RG-LRU라는 새로운 순환 유닛입니다. 이는 하드웨어 효율적인 요소별(Element-wise) 연산을 사용하여, RNN의 단점인 느린 학습 속도를 극복하고 트랜스포머 수준의 학습 효율을 달성했습니다.Hawk: 순수 RNN 기반 모델.Griffin: RG-LRU와 로컬 어텐션을 결합한 하이브리드 모델.Griffin은 Llama-2와 같은 트랜스포머 모델과 대등한 성능을 보이면서도, 추론 시에는 훨씬 적은 메모리와 빠른 속도를 제공합니다.217. Gemini 2.0과 구글의 통합 전략구글의 이러한 개별 연구들은 최신 플래그십 모델인 Gemini 2.0 시리즈에 통합되고 있습니다.23Test-Time Learning의 적용: Gemini 2.0 Flash와 같은 모델은 에이전트 작업 수행 시, 환경 피드백을 통해 추론 과정에서 전략을 수정하는 능력을 보여줍니다. 이는 Titans 연구에서 제안된 '추론 시점 학습/암기' 개념이 상용 모델에 적용되고 있음을 시사합니다.25무한 문맥과 멀티모달: 200만 토큰 이상의 긴 문맥 처리 능력은 Infini-attention과 MoD의 효율적인 연산 관리 기술 없이는 구현이 불가능에 가깝습니다. 구글 클라우드의 CTO 오피스는 Titans 논문의 수학적 파생 과정을 설명하며 이 기술들이 실제 구글의 AI 스택에 녹아들고 있음을 언급했습니다.278. 결론구글은 '트랜스포머 이후(Post-Transformer)'를 대비하여, 기억(Titans), 효율(MoD, JEST), 확장성(Infini-attention), 대안 아키텍처(Griffin) 전반에 걸쳐 독자적인 기술 포트폴리오를 완성했습니다. 특히 Titans의 등장은 AI가 정적인 함수에서 벗어나, 실시간으로 경험을 기억하고 적응하는 '동적인 지능'으로 진화하고 있음을 보여주는 구글의 가장 중요한 'Next Attention' 모멘트입니다.